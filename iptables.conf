#input section, what data do we want to collect 
input { 
#	stdin {
#		type => "iptables" 
#	}

	file { 
		type => "iptables" 
		path => "/home/michael/messages/*" 
		start_position => beginning
#		ignore_older => 0
	} 
} 

filter { 
	if [type] == "iptables" {
		grok { 
			match => {
				"message" => ["%{IPTABLES_MSG}"]
			}
		}

		date { 
			#use the field timestamp to match event time and               
			#populate @timestamp field (used by Elasticsearch) 
			match => [ "timestamp", "MMM dd HH:mm:ss"] 
			timezone => "Europe/London" 
		} 
	} 
#	geoip { 
#		#enrich both event types with geo fields based on the 
#		#src_ip field for analytics and drawing pretty maps 
#		source => "src_ip" 
#	} 
}

output { 
#events failing to match Grok definitions will be 
#automatically tagged with '_grokparsefailure' 
#in this case we want to send only events where 
#field extraction will be happening correctly 
	if "_grokparsefailure" not in [tags] { 
		if [type] == "iptables" { 
			csv {
				path => "/home/michael/iptables.csv"
				fields => ["tags","host","src_port","ttl","src_mac","prec","dst_port","dst_ip","src_ip","type","_host","action","length","ktime","tos","timestamp","in", "@timestamp","dst_mac","proto","id","frametype"]
				csv_options => {
					"write_headers" => true
				        "headers" =>["tags","host","src_port","ttl","src_mac","prec","dst_port","dst_ip","src_ip","type","_host","action","length","ktime","tos","timestamp","in", "@timestamp","dst_mac","proto","id","frametype"]
				}
			}

#	                stdout {
#	                       	codec => rubydebug
#         	     	}
		}	
	}  
	else { 
		#let's print to logstash standard output 
		#events not captured by our Grok definitions 
		file { 
			path => "/home/michael/grokparsefailure.txt"
		} 
	} 
}
